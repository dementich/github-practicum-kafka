# Как все это работает

1.	Задумка формулируется довольно просто: есть 7 пользователей (Трус, Балбес, Бывалый, Шурик, Нина, Саахов, Дядя), которые могут отправлять сообщения друг другу (в том числе самим себе).

2.	Для каждого из этих пользователей есть список заблокированных пользователей. И пользователи и те, с кем они не хотят общаться, перечислены в файле `users.json`.

3.	Инициализируются черные списки пользователей и цензурируемых слов. С технической точки зрения это выполняется модулем `messages_producer.py` с помощью параметров запуска `--black_list` и `--censored_words`. Пример можно видеть в пункте 6 раздела "Как воспроизвести работу".

4.	В определенный момент времени от случайного пользователя отправляется сообщение в адрес случайного пользователя. Данное сообщение содержит ряд слов, среди которых будет подлежащее цензурированию слово. С технической точки зрения генерация выполняется кодом из `message_producer.py` и сообщение отправляется в топик `messages`. Вместе с этим в топики `black_list` и `censored_words` могут быть отправлены и черные списки отправителей для каждого получателя и список цензурируемых слов (см параметры `messages_producer.py`).

5.	Отправленные сообщения обрабатываются и в случае, если отправитель не входит в черный список получателя, то сообщение идет получателю. При этом все цензурируемые слова заменяются на !!!CENSORED!!!. С технической точки зрения поступившие в топик messages сообщения обрабатываются агентами из модуля `messages_consumer.py`. Они обрабатываются с точки зрения цензуры и, если это допустимо с точки зрения фильтрации отправителей, отправляются в топик `filtered_messages`

# Как воспроизвести работу:

1.	Поднимаем кластер с kafka зайдя в каталог с файлом docker-compose.yaml и запустив команду docker compose -f docker-compose.yaml up -d. Ему надо, чтобы были свободны порты 9094, 9095, 9096, 8088 и 8085.

2.	Создаем топики:

```bash
ID=$(docker ps --no-trunc -aqf "name=lab03-kafka-0-1") && docker exec -it $ID /opt/bitnami/kafka/bin/kafka-topics.sh --create --topic blocked_users --bootstrap-server 127.0.0.1:9092 --partitions 8 --replication-factor 3
ID=$(docker ps --no-trunc -aqf "name=lab03-kafka-0-1") && docker exec -it $ID /opt/bitnami/kafka/bin/kafka-topics.sh --create --topic censored_words --bootstrap-server 127.0.0.1:9092 --partitions 8 --replication-factor 3
ID=$(docker ps --no-trunc -aqf "name=lab03-kafka-0-1") && docker exec -it $ID /opt/bitnami/kafka/bin/kafka-topics.sh --create --topic messages --bootstrap-server 127.0.0.1:9092 --partitions 3 --replication-factor 3
ID=$(docker ps --no-trunc -aqf "name=lab03-kafka-0-1") && docker exec -it $ID /opt/bitnami/kafka/bin/kafka-topics.sh --create --topic filtered_messages --bootstrap-server 127.0.0.1:9092 --partitions 3 --replication-factor 3
```

3.	Идем в браузере на 127.0.0.1:8080. Там должен отображаться пользовательский интерфейс kafka-ui и должно быть видно, что у нас 3 брокера

4.	Идем на localhost:8085 в раздел Topics и создаем топики `messages`(1 партиция), `filtered_messages` (3 партиции), `blocked_users` и `censored_words`(по 8 партиций в каждом)

5.	Предполагается, что все действия код выполняет в рамках определенного окружения на основе Python 3.9.23, что оно активно и что в этом окружении стоят библиотеки `confluent_kafka` и `faust`.

6.	Запускаем обработчик входящих сообщений командой `faust -A messages_consumer worker -l info`

7.	Запускаем генератор цензурируемых исходящих сообщений командой `./messages_producer.py --black_list --censored_words ./censored_words.json --message_count 25`. Для изменения цензурируемых слов можно сначала очистить их список, запустив `./messages_producer --censored_words ./no_censore.json`, а потом запустить продюсер с каким-нибудь новым файлом со списком подлежащих ценрузированию слов.

# Проблемы при работе

С технической точки зрения не реализовано одно требование: черные списки пользователей хранятся в оперативной памяти, а не в персистентном хранилище. Если в модуле `messages_consumer.py` попытаться инициализировать application с помощью закомментированной строки кода, то по идее все должно работать через персистентное хранилище, однако выполнить это не удалось из-за того, что не получается поставить библиотеки для rocksdb (Failed building wheel for python-rocksdb). Подробности того, что система выводит при запуске консюмера с использованием rocksdb можно видеть в файле `rocksdb_run.log`. Подробности сообщений, появляющихся при попытке выполнить команду `pip install python-rocksdb`, можно видеть в файле `rockdb_install.log`. Если кто-то подскажет, как это победить, обязательно попробую.
